---
title: "Data Carpentry Workshop 2022 Code"
author: "Erin Witkop"
date: "5/13/2022"
output: github_document

---
## DAY 1

### 9:00 am Introduction 

Welcome to the second data carpentry style workshop that the Bioinformatics group has hosted. My name is Erin Witkop, I am a Bioinformatics Postdoctoral Research Associate in Peter Linsley's lab and I started last October. I started coding in R as a undergrad and now have about 8 years of experience and about three years ago I became a certified Data Carpentry instructor, which means I have taken several of their courses, taught several prior courses, and have taken a course in the pedagogical style of the Carpentries. I really enjoy teaching and working with data and I'm excited to be teaching this course along with several fellow intructors Hannah DeBerg and Matt Dufort who are going to step in toward the end of the course.

This course is designed to start out with the assumption that you have no prior experience coding at all in any language and the curriculum is designed to build on itself throughout the course. Our main goals for the course are that in the future when you have your own data you will be able to load it into R, calculate some standard statisitcs, and do some exploratory plotting that you can share with your colleagues. 

We are basing the curriculum and pedagogical style of this course off of the Data Carpentries style, specifically the visusalizing ecology data course. 

For information regarding the schedule, helpful Data Carpentry resources, links to the code we will generate, and links to the collaborative etherpad document, please see our github repository [link](https://github.com/BenaroyaResearch/Data_Carpentry_Workshop_2022)

We are additionally going to use a collaborative etherpad document at several points during the course. The link for the etherpad is [here](https://pad.riseup.net/p/BRI_Data_Carpentry_2022).

Finally, I wanted our helpers for the workshop today:    . Every day we will have atleast two helpers who have experience with R Their role is to help troubleshoot any individual problems or error codes you may have that you are not able to figure out. Whenever you need help just raise up your red sticky note and a helper will come over and see if they can help assist you. At some points in the course I'll check in regarding the pace of the course and ask you to put up a green sticky note if you feel good, or red if I need to slow down and go slower.

I do want to point out that there are a lot of things to know about R, but the goal of this course is to help you build confidence and know that you find answers to your own questions.

### 9:10 am - 9:45am: Intro to R 

- What is R? What is RStudio?
  - The term “R” is used to refer to both the programming language and the software that          interprets the scripts written using it.

- Why learn R?
  - R is great for reproducibility, R can integrate new and existing tools, R is interdiscipinary and extensible, its free, is open source, R produces high quality graphics, large helpful community 
    - Stack overflow, R studio community
    
#### Knowing your way around R and R studio 

Let’s start by learning about RStudio, which is an Integrated Development Environment (IDE) for working with R.

The RStudio IDE open-source product is free under the Affero General Public License (AGPL) v3. The RStudio IDE is also available with a commercial license and priority email support from RStudio, PBC.

We will use RStudio IDE to write code, navigate the files on our computer, inspect the variables we are going to create, and visualize the plots we will generate. RStudio can also be used for other things (e.g., version control, developing packages, writing Shiny apps) that we will not cover during the workshop.

RStudio is divided into 4 “panes”:

  - The Source for your scripts and documents (top-left, in the default layout)
  - Your Environment/History (top-right) which shows all the objects in your working space (Environment) and your command history (History)
  - Your Files/Plots/Packages/Help/Viewer (bottom-right)
  - The R Console (bottom-left)

The placement of these panes and their content can be customized (see menu, Tools -> Global Options -> Pane Layout). For ease of use, settings such as background color, font color, font size, and zoom level can also be adjusted in this menu (Global Options -> Appearance).

One of the advantages of using RStudio is that all the information you need to write code is available in a single window. Additionally, with many shortcuts, autocompletion, and highlighting for the major file types you use while developing in R, RStudio will make typing easier and less error-prone.

#### Getting set up 

It is good practice to keep a set of related data, analyses, and text self-contained in a single folder, called the working directory. All of the scripts within this folder can then use relative paths to files that indicate where inside the project a file is located (as opposed to absolute paths, which point to where a file is on a specific computer). Working this way allows you to move your project around on your computer and share it with others without worrying about whether or not the underlying scripts will still work.

RStudio provides a helpful set of tools to do this through its “Projects” interface, which not only creates a working directory for you, but also remembers its location (allowing you to quickly navigate to it) and optionally preserves custom settings and (re-)open files to assist resume work after a break. Go through the steps for creating an “R Project” for this tutorial below.

  1. Start RStudio.
  2. Under the `File` menu, click on `New Project`. Choose `New Directory`, then `New Project`.
  3. Enter a name for this new folder (or “directory”), and choose a convenient location for it. This will be your working directory for the rest of the course (e.g., ~/data-carpentry).
  4. Click on Create Project.

A workspace is your current working environment in R which includes any user-defined object. By default, all of these objects will be saved, and automatically loaded, when you reopen your project.

#### Organizing your working directory

Using a consistent folder structure across your projects will help keep things organized, and will help you to find/file things in the future. This can be especially helpful when you have multiple projects. In general, you may create directories (folders) for scripts, data, and documents.

Let's create a few new folders to hold input and output for us in our repository
  - `/raw_data/`
  - `/scripts/`
  - `/figures/`
  - `/results/`

#### The working directory

The working directory is an important concept to understand. It is the place from where R will be looking for and saving the files. When you write code for your project, it should refer to files in relation to the root of your working directory and only need files within this structure.

RStudio assists you in this regard and sets the working directory automatically to the directory where you have placed your project in. If you need to check it, you can use `getwd()`. If for some reason your working directory is not what it should be you can use `setwd("/path/to/working/directory")` to reset your working directory.

#### Interacting with R

What we are writing is *code* or the instructions to tell R how to run. We call the instructions *commands* and then we execute the commands by running the code.

You can either run code directly through the console and press `Enter`, or by writing your commands in a script and running them using the `Run` button or a keyboard shortcut. For example, I run my commands in R on a mac using COMMAND+ENTER.

For reproducibility its best to write your code down in R and using the number (#) sign to include comments. Any line or part of a line starting with a number sign will be ignored by R. It's really important to comment your code, both for yourself and for sharing what you have done with others. 

#### Seeking help

You can search functions by typing `?mean()` in the console or also through the help tab in R studio. Looking up commands is really useful for understanding the arguments that each one takes and how to use it properly! 

#### Automatic Code Completion 

When you start typing code in R you can its tab completion to finish a command or object name that you were typing by hitting the tab button.

#### Dealing with Error Messages

Don’t get discouraged if your code doesn’t run immediately! Error messages are common when programming, and fixing errors is part of any programmer’s daily work. Often, the problem is a small typo in a variable name or a missing parenthesis. Watch for the red x’s next to your code in RStudio. These may provide helpful hints about the source of the problem.

RStudio shows a red x next to a line of code that R doesn’t understand.
RStudio shows a red x next to a line of code that R doesn’t understand.

If you can’t fix an error yourself, start by googling it. Some error messages are too generic to diagnose a problem (e.g. “subscript out of bounds”). In that case it might help to include the name of the function or package you’re using in your query.

### 9:45 - 10:30 am: Introduction to R 

#### Creating Objects in R 

You can get output from R simply by typing math in the console:

```{r math}
3 + 5
12 / 7
```

However to do things with this data we need to save it as an *object* by assigning the value to a name using the assignment operator `<-`

In RStudio, typing Alt + - (push Alt at the same time as the - key) will write <- in a single keystroke in a PC, while typing Option + - (push Option at the same time as the - key) does the same in a Mac.

```{r object}
age <- 50
```

R doesn't automatically print the output after you assign data to an object, so to view it you need to print the name of the object and run it

```{r object_print}
age
```

Objects can have almost any name you want, they just can't start with a number, have any spaces in them, or be the same name as one of the functions in R. R is case sensitive, and being consistent in your naming is helpful.  

For those of you familiar with any other coding languages, in R and `object` is the same thing as a `variable`. They are interchangable. 

Now that we have saved our data data as an object we can do math with it!

```{r age_math}
age * 2

# And we can save this output to a new object
age_double <- age * 2
```

You can also change the value by assigning a new one

```{r age_math_rename}
age <- 60
# Note this rewrites the previous data, but does not affect our doubled age object!

age_double

# So if you ever change a bit of code upstream, you need to rerun all the other commands that code depended on in order to update your data 
```

Let's do a quick challenge - put the answers to the following in the etherpad:

```{r challenge_1}
time_d <- 180
total_dosage_mg <- 500

# What is the dosage per day (mg)?
time_d/total_dosage_mg 

```

Now it's time to save your code! 

#### Functions and their arguments 

Functions are canned scripts that automate certain tasks, and all functions take arguments, and we can look these up using the help function! 

```{r sqrt}

age_sqrt <- sqrt(50)
age_sqrt

```

#### Vectors and Data Types 

A vector is the most common and basic data type in R, and is the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function. `c` stands for concatenate. However, all the elements in the vector have to be the same type of data.

```{r age_c}

# They can contain numbers
age_d <- c(50, 100, 150, 200)
age_d 

# Or characters
treatments <- c("saline","tetramer","IL-13")
treatments
```

Several functions allow you to inspect a vector. 

``` {r vector_inspect}
# To view the number of elements
length(treatments)

# To view the type of data 
class(age_d) 
class(treatments)

# view the structure 
str(treatments)
str(age_d)

```

There are several other important data structures in R that we will discuss as we move through the course, including `list`, `matrix`, data frames (`data.frame`), factors (`factor`) and arrays (`arrays`).

##### Subsetting Vectors 

To extract a value from a vector you need to provide and index in square brackets.

```{r index_vector}

drug <- c("aspirin","tylenol","sudafed")

# to extract the third and second elements
drug[c(3,2)]

```

##### Conditional Subsetting

```{r condition}
weight_g <- c(25,30,35,40)

# Can ask a logical question
weight_g > 20
weight_g < 30

# you can also select values that meet a condition
weight_g[weight_g < 40]

# Or combine multiple tests with AND `&` and OR `|`
weight_g[weight_g <=30 | weight_g == 40]
```

You can also search for a list of strings in a vector using the `%in%` function 

```{r search}
months <- c("Jan","Feb","Mar","Apr")

# Use logical vector to find matches between lists
months[months %in% c("Jan","Mar","July")]

```

```{r challenge_2}

# can you find values between 100 and 200 in this list?
weight_lb <- c(55,95,105,187, 201)

```

##### Missing Data

Missing data in vectors is returned as `NA`. In some function you can add `na.rm = TRUE` to remove the `NA`s. 

```{r missing}
heights <- c(2,4,4,NA,6)
mean(heights) # why didn't this work?
mean(heights, na.rm = TRUE)

# You can also select for all values that are not NAs
heights[!is.na(heights)]

# You can also omit NAs
heights <- na.omit(heights)

```

```{r challenge_3}

# Can you return this data frame with no NAs?

weight_g <- c(10,15,16, NA,25, 30, NA)

```

### BREAK: 10:30 - 10:45 ####

### 10:45-11:15: Starting with Data in R: Dataframes ####

#### Downloading the Data

Now it's time to download a subset version of the COVID-19 data. The data is saved in a csv file and is saved on our Github landing page. https://github.com/BenaroyaResearch/Data_Carpentry_Workshop_2022/blob/main/WORKSHOP_DATA/Bolouri_2021_subset.csv

Let's open the csv table in EXCEL and view it. We have patient metadata, CYTOF data, and initial CBC counts for different cell populations. The data is in different formats also. 

Download the data to your raw_data folder 

```{r read_csv}
library(tidyverse)
setwd("/Users/ewitkop/Library/CloudStorage/Box-Box/EW_Bioinformatics_Postdoc_Research/ADMINISTRATIVE/Data_Carpentry_Workshop_June_2022/WORKSHOP_CODE/Data_Carpentry_Workshop_2022/")
data <- read_csv("raw_data/Bolouri_2021_subset.csv")

```

Note how read csv looks at the data type of each column. 

#### Inspecting data frames

```{r investigate}

# To view whole dataset
print(data,100)

# To see the first few lines
head(data)
head(data, 100)

# To see last few lines
tail(data)

# To open in R studio
View(data)

# additional helpful commands
nrow(data)
ncol(data)
rownames(data)
summary(data)

```

What we just loaded was a dataframe, the typical data structure used in R for tabular data while we will use for statistics and plotting.

In a dataframe columns are vectors of the same length and same type of data. 

```{r challenge_4}
# Based on the output of str(data), what is the class of our data object? How many rows and columns are there? 

str(data)
nrow(data) # 299
ncol(data) # 26
```

#### Indexing and subsetting data frames

To extract data from a data frame we need to use its coordinates, which are always row number followed by column number.

```{r index }
# get first row and column
data[1,1]

# You can save this by assigning it to a variable
data_subset <- data[1,1]

# get only 5th columns
data[,5]

# select group of rows and columns
data[1:2,3:6]

# You can also exclude columns using the minus sign
data[,-1]

# To get only the head of the dataframe you can do
data[-(7:nrow(data)),]

# You can also subset by using the name of the column in quotation marks
data[, "Sample.ID"]

# Finally you can also use the $ to get a column
data$Sample.ID

```

Challenge time!
```{r challenge_5}
# Create a data.frame (data_200) containing only the data in row 200 of the surveys dataset.
data_200 <- data[200,]

# Pull out the last row of the data frame and save it
nrow(data) # 299
data_last <- data[299,]
```

Let's take five minutes for this challenge so you can have a breather before starting the final piece of our first day! 

### 11:15-12:00pm: Starting with Data in R Cont: 

#### Factors 

Several of our data columns contain character data that are categorical variables. `Factor` is a special class used for working with categorical data. Factors only contain a list of pre-defined levels. Though factors may often look like character vectors, they are actually treated as integer vectors, so you need to be careful when treating them as strings.

```{r factors}

# Use the factor function to convert column levels to factors 
data$sex <- factor(data$sex) 

# check the conversion worked with summary and class
summary(data$sex)
class(data$sex)

# Note that factors are always assigned in alphabetical order. Check the levels of a factor with levels
levels(data$sex) # see that female comes before male

# Get the number of levels with n level 
nlevels(data$sex)
  
```

Sometimes you may want your levels in specific order.

```{r factor_reorder}
data$sex <- factor(data$sex, levels = c("male","female"))
levels(data$sex)

```

Challenge
```{r challenge_6}
# Convert the HigestCare column to a factor and put the levels in this order: Neg, Floor, CCU, Outpatient

levels(as.factor(data$HighestCare)) # "CCU"        "Floor"      "Neg"        "Outpatient"
data$HighestCare <- factor(data$HighestCare, levels = c("Neg","Floor","CCU","Outpatient"))
```

#### Converting factors

To convert a factor to character vector you can use `as.character(x)`

```{r convert_factor}
as.character(data$sex)

```

#### Renaming Factors 

With your data stored as factors you can use the `plot()` function to quickly see the number of observations in each factor level

```{r plot_factor}
plot(data$HighestCare)
```
However say we wanted to rename the Negative group from Neg to Negative.

```{r rename_factor}

levels(data$HighestCare)[1] <- "Negative"
plot(data$HighestCare)
```
We can also use this to rename any NA levels we may have. For example, lets make the `Ever.On.Ventilator` column a factor and plot it.

```{r rename}
data$Ever.On.Ventilator <- factor(data$Ever.On.Ventilator)
plot(data$Ever.On.Ventilator)

# But what about the NAs samples that we know are there?

# turn the missing values into a factor levels with the addNA() function
data$Ever.On.Ventilator <- addNA(data$Ever.On.Ventilator)
levels(data$Ever.On.Ventilator)

# And rename the NA
levels(data$Ever.On.Ventilator)[3] <- "Not Applicable"

# now we can replot and see this new added level
plot(data$Ever.On.Ventilator)

```
Challenge!
```{r challenge_7}
# Now that we have renamed the Ever.On.Ventilator column, can you reorder the levels so that the "Not Applicable" patients are plotted before  the "N" patients?
data$Ever.On.Ventilator <- factor(data$Ever.On.Ventilator, levels = c("Not Applicable","N","Y"))

plot(data$Ever.On.Ventilator)
```
#### Saving and exporting data

Now that we have done a variety of data manipulations, we want to save our output.

```{r write_day}

# lets output in our results folder
write.csv(data, file="Data_Carpentry_Workshop_2022/results/data_day1.csv", row.names = FALSE)


```

When you close out R Studio you will see the option to save your current session objects. I typically do, though sometimes this can get you into troubl as you are approaching the edge of R's memory. 

#### END OF DAY 1 

## DAY 2

### 9:00am: Manipulating Data in R

Using brackets to subset data can be cumbersome, so in comes the `dplyr` package which has a set of functions designed for tabular data manipulation. The `tidyverse` package we loaded yesterday already includes this package as well as a few others, like `ggplot2`, `tidyr` which we will use today. The `tidyr` allows for more simple reshaping of the data for plotting and other data analysis tasks. Note that online and in R studio there are helpful cheatsheets that have a list of functions in both `dplyr` and `tidyr` that are very useful references. 

To access go to `Help` > `Cheatsheets`

```{r library}
# Note that every time you restart R you need to reload your packages

library(tidyverse)

# Let's also load in our data that we exported yesterday at the end of our session
data2 <- read_csv("Data_Carpentry_Workshop_2022/results/data_day1.csv")

```
Now we're going to learn some of the most useful `dplyr` data manipulation functions.

  - `select()`: subset columns
  - `filter()`: subset rows on conditions
  - `mutate()`: create new columns by using information from other columns
  - `group_by()` and `summarize()`: create summary statistics on grouped data
  - `arrange()`: sort results
  - `count()`: count discrete values

#### Selecting columns and filtering rows

```{r select}
select(data2, Sample.ID, age, bmi) # put the name of the df first, followed by the columns names

# use the minus "-" symbol to select all except certain columns
select(data2, -sex, -race)

# you can also select rows based on certain criteria using filter
filter(data2, HighestCare == "Outpatient")
filter(data2, age <= 50)

```
#### Pipes

What if you want to filter and select at the same time? You can either do this in intermediate steps, nesting functions, or running the functions one after the other on the same dataset using pipes. 

```{r pipes}

# Intermediate steps
data2_subset <- filter(data2, bmi < 30)
data2_subset <- select(data2_subset, Sample.ID, age, severity)

# Nest the functions
data2_subset <- select(filter(data2, bmi < 30), Sample.ID, age, severity)

# nesting  can get hard to read

# Use the pipe operator %>% 
# Pipes in R look like %>% and are made available via the magrittr package, installed automatically with dplyr. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac.

data2 %>%
  filter(bmi < 30) %>% 
  select(Sample.ID, age, severity)

# the pipe passes the data from one operation to another and goes step by step, it is like saying the word "then" at each pipe 

# We can create a new object with this filtered data
data2_sml <- data2 %>%
  filter(bmi < 30) %>% 
  select(Sample.ID, age, severity)

data2_sml

```
Challenge
```{r challenge_8}
# Using pipes, subset data2 to keep only patients with a COVID score at or below 4, whose highest care was NOT CCU, and retain only their Sample.ID, age, sex, and bmi.

data2_subset <- data2 %>% 
  filter(Score <= 4) %>% 
  filter(HighestCare != "CCU" ) %>%
  select(Sample.ID, age,sex, bmi)

```
#### Mutate

It is often the case that you want to perform some manipulation on an existing column and make a new column. You can do this using the function `mutate`

```{r mutate}
# lets create a new column where we calculate a persons age in months
data2 %>%
  mutate(age_months = age*12)

# Can also do multiple mutates one after the other
data2 %>% 
  mutate(age_months = age*12,
         age_d = age_months*30)

# Pipes work with non plyr functions as well. For example, we canAdd head() to view the first #few rows
data2 %>% 
  mutate(age_months = age*12,
         age_d = age_months*30) %>%
  head()


```
Let's say we now wanted to calculate the mean bmi of measured patients.

```{r mean_bmi}

data2_mean_bmi <- data2 %>% 
  mutate(mean_bmi = mean(bmi))
data2_mean_bmi$mean_bmi # this returns all NA's? Why?

# Let's view the original data
data2$bmi # as we can see there are a few NA's here that are preventing our calculation from running correctly

# we can filter out these NAs and then run the function
data2 %>%  
  filter(!is.na(bmi)) %>%
  mutate(mean_bmi = mean(bmi)) %>%
  View()
```
Challenge 
```{r challenge_9}

# Create a new data frame that contains only the Sample.ID column and a column showing the mean score, and only has contains patients older than 40.  

data_new <- 
  data2 %>%
  filter(!is.na(Score)) %>%
  mutate(mean_score = mean(Score)) %>%
  filter(age >= 40) %>%
  select(Sample.ID, mean_score)

```
#### Split-apply-combine data analysis and the `summarize()` function

Many tasks involve splitting the data to perform a function, applying the function, and then re-combining the data. The key `dplyr` functions for this are `group_by()` and `summarize()`.

The `group_by()` function allows you to group together rows by categorical variables. When used with `summarize()` you can apply a summary function to a specific grouping of the data and output a single result, or summary, per group.

```{r summarize}
# to compute mean bmi by sex we can do the following
data2 %>% 
  group_by(sex) %>%
  summarize(mean_bmi = mean(bmi, na.rm = TRUE))

# you can also group by multiple columns
data2 %>%
  group_by(sex, race) %>%
  summarize(mean_bmi = mean(bmi, na.rm = TRUE)) %>%
  #can use tail to look at end of the output
  tail()

# After the data is grouped you can also summarize multiple variables at the same time
data2 %>%
  group_by(sex, race) %>%
  summarize(mean_bmi = mean(bmi, na.rm = TRUE),
            max_bmi = max(bmi, na.rm = TRUE))

# You can also rearrange the output to make it more readable
data2 %>%
  group_by(sex, race) %>%
  summarize(mean_bmi = mean(bmi, na.rm = TRUE),
            max_bmi = max(bmi, na.rm = TRUE)) %>%
  arrange(max_bmi)

# To sort in descending order you need add the `desc()` function to the `arrange` function
data2 %>%
  group_by(sex, race) %>%
  summarize(mean_bmi = mean(bmi, na.rm = TRUE),
            max_bmi = max(bmi, na.rm = TRUE)) %>%
  arrange(desc(max_bmi))

```

#### Counting

It's often useful to know the number of observations in a particular group.

```{r count}
# if we wanted to count the number of people in each sex
data2 %>%
  count(sex)

# The count function behind the scenes is grouping by a variable and then summarizing it by counting the observations in that group
data2 %>%
  group_by(sex) %>%
  summarise(count = n())

# Count also allows you to sort
data2 %>%
  count(sex, sort = TRUE)

# Count by a number of factors
data2 %>% 
  count(sex, race) 

# next we can arrange this to have a better look, alphabetical by sex, and descending by count
data2 %>% 
  count(sex, race) %>%
  arrange(sex, desc(n))

```

Challenge 10
```{r challenge_10}
# How many male patients had severe covid?
data2 %>%
  count(sex, severity)

# Use group_by and summarize to find the mean, max and min White Blood cell count of patients by COVID severity group, also add the number of observations
data2 %>%
  group_by(severity) %>%
  filter(!is.na(CBC.White.Blood.Cell.Count)) %>%
  summarize(mean_WBC = mean(CBC.White.Blood.Cell.Count),
            max_WBC = max(CBC.White.Blood.Cell.Count),
            min_WBC = min(CBC.White.Blood.Cell.Count),
            n = n())

```

### 10:15am-10:30am: BREAK

### 10:30am-12:00am: Reshaping data and Visualizing Data with ggplot2 

#### Reshaping data with pivot_wider and pivot_longer

There are several key principles that we follow to stucture a "tidy" dataset:

  1. Each variable has its own column
  2. Each observation has its own row
  3. Each value must have its own cell
  4. Each type of observational unit forms a table

Our data currently violates principle 2 of this list because the CBC columns and CYTOF panel columns have different observations in each column in a single row. Because of this, these columns are currently in what is known as `wide` format. We can reorganize this data into `long` format so that there is truly one observation per row by using `pivot_longer`. If afterwards we wanted to switch the data back to wide format we could use `pivot_wider()`. 

There are several older, deprecated functions that perform these tasks called `gather()` (`pivot_longer`) and `spread()` (`pivot_wider`). 

```{r pivot_longer}

# let's first look at the man page for this 
?pivot_longer()

# and get the list of columns we want to convert
colnames(data2)

# pivot the data
data_long <- data2 %>%
  pivot_longer(cols = c("CBC.White.Blood.Cell.Count", "CBC.Absolute.Monocytes",    
  "CBC.Absolute.Neutrophils", "CBC.Absolute.Lymphocytes"),
  names_to = "CBC",
  values_to = "Counts") 
View(data_long)  
  
# now time to pivot the other columns
data_long <- data_long %>%
  pivot_longer(cols = c("FracCD45.Neutrophil","FracCD45.T.cell.CD4",       
  "FracCD45.DC", "T.cell.CD8.HLA_DRp__of.CD8" ),
  names_to = "CYTOF",
  values_to = "Fraction")

```
### Visualizing Data in R with ggplot

The `ggplot2` package has many helpful commands for plotting data in a data.frame. Allows you to create publication quality plots by fine tuning all the aspects of how the plots appear. `ggplot2` is the name of the package itself, while `ggplot` is the name of the plotting function. `ggplot` works best with data in long format.

ggplot graphics are built layer by layer so you continualy add on new components. 

The basic template for a ggplot is `ggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) + <GEOM_FUNCTION>()`

```{r ggplot_intro}
# start with a dataframe and the mapping
ggplot(data = data_long, mapping = aes(x = bmi, y = age)) 

# see how we have the outline of the plot, but no plot itself
ggplot(data = data_long, mapping = aes(x = bmi, y = age)) + geom_point()

# geoms are graphical representations of the data and there are multiple different geoms

# Note that the `+` sign allows you to add new features to your plots

# You can also save your base plot and add features to it after the fact
data_plot <- ggplot(data = data_long, mapping = aes(x = bmi, y = age))

data_plot + geom_point()

# Note that the correct syntax is to put the `+` sign on the line before you add the new layer
data_plot +
  geom_point()

data_plot
#+ geom_point() # this doesn't work

```

Now we can start modifying the plots!

```{r ggmodify}

# you can add transparency to the points
ggplot(data = data_long, mapping = aes(x = bmi, y = age)) + 
  geom_point(alpha = 0.05) # only affects overlapping points

# you can also add color to the points using a few different mechanisms
ggplot(data = data_long, mapping = aes(x = bmi, y = age)) + 
  geom_point(alpha = 0.05, color = "blue")

# you can also color by group
ggplot(data = data_long, mapping = aes(x = bmi, y = age, color =sex  )) + 
  geom_point(alpha = 0.05)

# this is equivalent to the following
ggplot(data = data_long, mapping = aes(x = bmi, y = age  )) + 
  geom_point(alpha = 0.05, aes(color = sex))
```
Challenge
```{r challenge_11}

# Can you plot relationship between severity and age with points, and color by sex?
ggplot(data = data_long, mapping = aes(x = severity, y = age, color = sex )) + 
  geom_point()

```

#### Boxplot

A better way to view the data from this example is as a boxplot! Let's try.

```{r boxplot}
ggplot(data = data_long, mapping = aes(x = severity, y = age, color = sex )) + 
  geom_boxplot()

# We can also add points to this plot to better view the distribution of the underlying data 
ggplot(data = data_long, mapping = aes(x = severity, y = age, color = sex)) + 
  geom_boxplot(alpha = 0) +
  geom_point(alpha = 0.3) 

# But we want to separate the points by group, we can specify this in our point argument
ggplot(data = data_long, mapping = aes(x = severity, y = age, color = sex)) + 
  geom_boxplot(alpha = 0) +
  geom_point(aes(group = sex) ,alpha = 0.3, position = position_dodge(width = 0.75))

```
An alternative to the boxplot that allow you to better view the shape of the data is a violon plot.

```{r violin}
ggplot(data = data_long, mapping = aes(x = severity, y = age, color = sex)) + 
  geom_violin(alpha = 0) +
  geom_point(aes(group = sex) ,alpha = 0.3, position = position_dodge(width = 0.9))

```
Challenge
```{r challenge_12}

# Can make a boxplot of bmi by Patient Type and color by Highest Care?

# note that you dont have to say data = or mapping = 
ggplot(data_long, aes(x = patientType, y = bmi, color = HighestCare)) +
  geom_boxplot() +
  geom_point(aes(group = HighestCare), position = position_dodge(width = 0.75))
```

Before we depart for the day, let's again save our data for use tomorrow.

```{r write2}

# lets output in our results folder
write.csv(data_long, file="Data_Carpentry_Workshop_2022/results/data_day2.csv", row.names = FALSE)

```

#### END OF DAY 2 

## DAY 3 

### 9:00am-10:15am: Visualizing Data Continued

Now that we have learned some of the foundational skills for making plots, the goal for today is to really expand our skill set for modifying plots and build toward trying to recreate some plots that were originally published in the Bolouri et al. 2021 paper.

```{r begin_day3}
library(tidyverse)

data_day3 <- read_csv("Data_Carpentry_Workshop_2022/results/data_day2.csv")

# Let's remind ourselves what the data looks like
View(data_day3)

```

#### Pipes

As a first way to expand our skill set let's talk about use of the pipe operator with ggplot. Just like with the dplyr commands we learned yesterday, we can use the pipe operator to subset and filter data prior to plotting.

```{r ggplot_pipe}

# to demonstrate this lets plot the CBC White Blood Cell Count data by Covid SCORE as a boxplot
# we'll first view this data
data_day3 %>%
  filter(CBC == "CBC.White.Blood.Cell.Count") %>% View()

# Notice that we have duplicates in our CBC column! We need to collapse these duplicates in our plot
data_day3 %>%
  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>% View()

# Now we can plot
#data_day3 %>%
#  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
#  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>% 
#  ggplot(aes(x = Score, y = Counts)) + 
#  geom_boxplot()

# This gives us an error, why?
data_day3$Score # there are a lot of NA's at the beginning of the data, let's remove these
data_day3 %>%
  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>% 
  filter(!is.na(Score)) %>%
  ggplot(aes(x = Score, y = Counts)) + 
  geom_boxplot()

# This give us only one bar across, why? We need to add the grouping
data_day3 %>%
  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>% 
  filter(!is.na(Score)) %>%
  ggplot(aes(x = Score, y = Counts, group = Score)) + 
  geom_boxplot()

# You'll also notice that on our x axis we are only seeing score 2,4, and 6. This indicates that Score is being read as numerical. However, we want it to be viewed as a factor. Let's change this
class(data_day3$Score)
levels(as.factor(data_day3$Score))

# set the factor levels
data_day3$Score <- factor(data_day3$Score, levels = c("2", "3", "4" ,"5", "6", "7"))
class(data_day3$Score) # factor
View(data_day3)

data_day3 %>%
  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>% 
  filter(!is.na(Score)) %>%
  ggplot(aes(x = Score, y = Counts, group = Score)) + 
  geom_boxplot()
# now we see every level being represented 

```

Challenge
```{r challenge_13}
# Can you produce a boxplot of FracCD45.Neutrophil by Highest Care and also show all the individual data points?

data_day3 %>%
  filter(CYTOF == "FracCD45.Neutrophil") %>%
  ggplot(aes(x = HighestCare, y = Fraction, group = HighestCare)) + 
  geom_boxplot() +
  geom_point(alpha = 0.1)

```
#### Plot modification: Themes, colors, titles, facets 

Now that we can subset our data to make plots, let's learn how to modify the plot aesthetics in order to recreate plots from Figure 5c from the Bolouri et al., paper. https://www.jci.org/articles/view/143648.In this figure patients were grouped based on their disease severity, mild (cyan), moderate (blue), and severe (red), and SARS-CoV-2–negative hospitalized controls (gray). 

```{r ggplot_theme}

# Let's start with the same CBC.White.Blood.Cell.Count we plotted before and save the data
WBC <- data_day3 %>%  
  filter(CBC == "CBC.White.Blood.Cell.Count") %>%
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) 

# Now lets change the theme
WBC %>% 
  ggplot(aes(x = severity, y = Counts)) + 
  geom_boxplot() +
  # let's also change the theme to bw
  theme_bw()
```

Note that there are a variety of different themes available that you can see when you start typing theme.. Some of these include `theme_minimal()`, `theme_void()`, and `theme_light()`. 

```{r axes}
# Now we can add in the points to the boxplot
WBC %>% 
  ggplot(aes(x = severity, y = Counts)) + 
  geom_boxplot() +
  geom_point() +
  theme_bw()

# Now let's change the axes and graph titles
WBC %>% 
  ggplot(aes(x = severity, y = Counts)) + 
  geom_boxplot() +
  geom_point() +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells")
```

Next up we want to change the order of the severity data for plotting. We can do this by make Severity a factor and changing the order of the levels

```{r reorder}
class(WBC$severity) # character

# Let's make severity a factor
WBC$severity <- factor(WBC$severity , levels= c("Mild","Moderate","Severe","Neg"))

levels(WBC$severity)
                             
```

Next up let's change the colors of the plot. There are multiple ways that colors can be modified and the function you use to modify the colors depends on the arguments in your aesthetics mapping.

```{r plot_colors}

# Remember mild (cyan), moderate (blue), and severe (red), and SARS-CoV-2–negative hospitalized controls (gray)
WBC %>% 
  # first add the color argument to the mapping 
  ggplot(aes(x = severity, y = Counts, color = severity)) + 
  geom_boxplot() +
  geom_point() +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_color_manual(values = c("cyan","blue", "red","gray"))

# Next up to make our plot more comparable to the publication, lets make the boxplot be filled in with solid colors
WBC %>% 
  # change the color to fill
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # add specif
  geom_point() +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(values = c("cyan","blue", "red","gray"))

# however when we do this we lose our point colors, so let's add those back into geom_point
WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray"))

```
Next let's add the black trend lines and the gray bar to show the normal clinical values. 

```{r lines}
# we can add in horizontal lines by using geom_hline and specifying the y limits
WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray")) +
  geom_hline(yintercept = 4) + 
  geom_hline(yintercept = 11)

# How can we make the line dashed?
# google it!
WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray")) +
  geom_hline(yintercept = 4, linetype = "dashed") + 
  geom_hline(yintercept = 11, linetype = "dashed")

```

Finally, let's change the labels of the legend. There are multiple ways to change the labels. We could have changed the labels originally when we were changing the Severity to a factor, by specificying the labels as an argument there. We can also change them when we are specifying our colors.

```{r labels }
WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(labels = c("Mild COVID-19", "Moderate COVID-19", "Severe COVID-19", "Hospitalized COVID-19 Negative"), values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray")) +
  geom_hline(yintercept = 4, linetype = "dashed") + 
  geom_hline(yintercept = 11, linetype = "dashed")

# Notice now we have two legends now! we don't want this! Let's remove the legend for scale_color_manual
WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(labels = c("Mild COVID-19", "Moderate COVID-19", "Severe COVID-19", "Hospitalized COVID-19 Negative"), values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray"), guide = "none") +
  geom_hline(yintercept = 4, linetype = "dashed") + 
  geom_hline(yintercept = 11, linetype = "dashed") 
```

Finally let's change our legend title by using the theme function

```{r theme}

WBC %>% 
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(labels = c("Mild COVID-19", "Moderate COVID-19", "Severe COVID-19", "Hospitalized COVID-19 Negative"), values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray"), guide = "none") +
  geom_hline(yintercept = 4, linetype = "dashed") + 
  geom_hline(yintercept = 11, linetype = "dashed") +
  theme(legend.title = element_blank())

```
Previously we customized the plotting for just the CBCs. Instead of plotting one parameter at a time we can also generate a plot that has each parameter side by side.

```{r facet}
facet_CBC <- data_day3 %>%  
  distinct(Counts, CBC, Sample.ID, .keep_all = TRUE) %>%
  ggplot(aes(x = severity, y = Counts, fill = severity)) + 
  geom_boxplot() +
  # specify the color in geom_point
  geom_point(aes(color = severity),alpha = 0.5) +
  theme_bw() + 
  # you can change the x and y axis labels and the title labels using labs()
  labs(x = NULL, y = "Absolute Counts", title = "White Blood Cells") +
  scale_fill_manual(labels = c("Mild COVID-19", "Moderate COVID-19", "Severe COVID-19", "Hospitalized COVID-19 Negative"), values = c("cyan","blue", "red","gray")) +
  # we also need to specify the color here
  scale_color_manual(values = c("cyan","blue", "red","gray"), guide = "none") +
  theme(legend.title = element_blank()) + 
  facet_grid(.~CBC)

```

### 10:15-10:30: BREAK

### 10:30-12:00pm: Customized plotting cont.:

For the second part of this morning's session we are going to take what we learned this morning and apply it to recreate another one of the figures from Bolouri et al., specifically Figure 10d. 

Let's all take a look at the figure. Together we are going to work on correctly subsetting the data for this figure and then it would be great if you could work in groups of 3 or 4 to use the skills we've learned to put together as much of the figures as you can. And remember, if you forget how to do something, google is your friend! Forums like stack overflow usually have excellent answers. 

```{r handson}

# let's remind ourselves of our CYTOF data we have to work with 
levels(as.factor(data_day3$CYTOF)) # "FracCD45.DC"                "FracCD45.Neutrophil"        "FracCD45.T.cell.CD4"        "T.cell.CD8.HLA_DRp__of.CD8" we will focus on plotting these! 

# we also want to separate the data measurements by before and after toclizumab
# How can we find this - lets look at the date columns 

data_day3_10d <- data_day3 %>%
  # filter for patients that were given tocilizumab and have start and end dates
  filter(!is.na(tocilizumab.StartDate) & !is.na(tocilizumab.EndDate)) 
View(data_day3_10d)  

# You can notice that the start date and end dates are the same for all of these measurements
all(data_day3_10d$tocilizumab.StartDate == data_day3_10d$tocilizumab.EndDate) # TRUE

# next lets check the class of the date columns
class(data_day3_10d$tocilizumab.StartDate) # numeric
class(data_day3_10d$tocilizumab.EndDate) # numeric
class(data_day3_10d$drawDate) # numeric

# since they are all numeric formatted we should be able to use numerical logical statements to get our before and after

# next we are going to do a conditional mutate to label the measurements that were before or after tocilizumab
data_day3_10d <- data_day3_10d %>% mutate(tocilizumab.timing = case_when(
  drawDate >= tocilizumab.StartDate ~ "after_tocilizumab",
  drawDate < tocilizumab.StartDate ~ "before_tocilizumab"
))

head(data_day3_10d)

# finally, lets transform the CYTOF data to percentages, lets look at the data
head(data_day3_10d) # we can see that the CYTOF fields called "frac" start with 
data_day3_10d <- data_day3_10d %>% mutate(CYTOF_perc = Fraction*100)

```
Now we have our data correctly formatt it's time to try to recreate as much of the plot in this figure as you can. Let's start with a timeframe of 20 minutes working in small groups, and then we will come back together to go over the solution. 

```{r fiure_10d}
data_day3_10d_neutrophils <- data_day3_10d %>%
  filter(CYTOF == "FracCD45.Neutrophil") %>%
  distinct(eventId, .keep_all = TRUE) %>%
  mutate(percentage = Fraction*100) %>%
  group_by(Covid.ID, tocilizumab.timing) %>% 
  summarize(mean_perc = mean(percentage)) %>%
  ggplot(aes(x = tocilizumab.timing, y = mean_perc, color = tocilizumab.timing)) +
  geom_boxplot() +
  geom_point(aes(color = tocilizumab.timing, group = Covid.ID)) +
  geom_line(aes( group = Covid.ID), color = "grey") +
  theme_classic() + 
  scale_y_continuous(limits = c(0,100)) +
  scale_color_manual(name = NULL, labels = c("After Tocilizumab","Before Tocilizumab"), values = c("#00c7ff", "#fe5750"))+
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = NULL, y = "% of CD45", title = "Neutrophils")

data_day3_10d_CD4 <- data_day3_10d %>%
  filter(CYTOF == "FracCD45.T.cell.CD4") %>%
  distinct(eventId, .keep_all = TRUE) %>%
  mutate(percentage = Fraction*100) %>%
  group_by(Covid.ID, tocilizumab.timing) %>% 
  summarize(mean_perc = mean(percentage)) %>%
  ggplot(aes(x = tocilizumab.timing, y = mean_perc, color = tocilizumab.timing)) +
  geom_boxplot() +
  geom_point(aes(color = tocilizumab.timing, group = Covid.ID)) +
  geom_line(aes( group = Covid.ID), color = "grey") +
  theme_classic() + 
  scale_y_continuous(limits = c(0,15)) +
  scale_color_manual(name = NULL, labels = c("After Tocilizumab","Before Tocilizumab"), values = c("#00c7ff", "#fe5750"))+
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = NULL, y = "% of CD45", title = "T cells")

data_day3_10d_DC <- data_day3_10d %>%
  filter(CYTOF == "FracCD45.DC") %>%
  distinct(eventId, .keep_all = TRUE) %>%
  mutate(percentage = Fraction*100) %>%
  group_by(Covid.ID, tocilizumab.timing) %>% 
  summarize(mean_perc = mean(percentage)) %>%
  ggplot(aes(x = tocilizumab.timing, y = mean_perc, color = tocilizumab.timing)) +
  geom_boxplot() +
  geom_point(aes(color = tocilizumab.timing, group = Covid.ID)) +
  geom_line(aes( group = Covid.ID), color = "grey") +
  theme_classic() + 
  scale_y_continuous(limits = c(0,2)) +
  scale_color_manual(name = NULL, labels = c("After Tocilizumab","Before Tocilizumab"), values = c("#00c7ff", "#fe5750"))+
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = NULL, y = "% of CD45", title = "DCs")

data_day3_10d_DR_CD8 <- data_day3_10d %>%
  filter(CYTOF == "T.cell.CD8.HLA_DRp__of.CD8") %>%
  distinct(eventId, .keep_all = TRUE) %>%
  # it's already a percentage!
  #mutate(percentage = Fraction*100) %>%
  group_by(Covid.ID, tocilizumab.timing) %>% 
  summarize(mean_perc = mean(Fraction)) %>%
  ggplot(aes(x = tocilizumab.timing, y = mean_perc, color = tocilizumab.timing)) +
  geom_boxplot() +
  geom_point(aes(color = tocilizumab.timing, group = Covid.ID)) +
  geom_line(aes( group = Covid.ID), color = "grey") +
  theme_classic() + 
  scale_y_continuous(limits = c(0,50)) +
  scale_color_manual(name = NULL, labels = c("After Tocilizumab","Before Tocilizumab"), values = c("#00c7ff", "#fe5750"))+
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = NULL, y = "% of CD8", title = "HLA-DR+ CD8+ T cells")
      

```
#### Arranging and Exporting Plots

As a final step to make a publication ready figures, we can arrange and export the plots from R. There are several packages you can use for arranging and exporting plots.

```{r ggsave}

# one of the most commonly used to save ggplots is ggsave
ggsave(data_day3_10d_DR_CD8, file = "./Data_Carpentry_Workshop_2022/figures/data_day3_10d_DR_CD8.pdf", device = "pdf", height = 5, width = 5)

```

The package `ggpubr` with the `ggarrange` function is also extremely useful for allowing combination of multiple plots and adding labels for plotting. 

```{r ggarrange}
#install.packages("ggpubr")
library(ggpubr)

# now we can use ggarrange to combine all the plots
combined_plots <- ggpubr::ggarrange(data_day3_10d_neutrophils, data_day3_10d_CD4, data_day3_10d_DC, data_day3_10d_DR_CD8,
                            nrow = 1, labels = c("A","B","C","D"))

ggsave(combined_plots ,  file = "./Data_Carpentry_Workshop_2022/figures/combined_plots.pdf", device = "pdf",
       height = 3, width = 15)

```


Challenge 
```{r challenge_14}

# can you export the plot so that only the neutrophils and DCs and plotted in a single column (one on top of the other)
neutrophil_DC_plots <- ggpubr::ggarrange(data_day3_10d_neutrophils,  data_day3_10d_DC,  nrow = 2, ncol =1, labels = c("A","B"))

ggsave(neutrophil_DC_plots ,  file = "./Data_Carpentry_Workshop_2022/figures/neutrophil_DC_plots.pdf", device = "pdf",
       height = 5, width = 3)

```

#### END OF DAY 3 

# DAY 4 

### 9:00am-10:15: Specialized plotting (PCAs, heatmaps)

On this final day of the workshop we are going to delve into some more specialized plotting examples that many of you may encounter in your work. One of the most common of these is generating PCAs and heatmaps. Let's start with a PCA. There are many different packages for generating one. We will work today with the package `PCAtools`.

In order to plot a PCA in R you need to have all your variables of interest set up as a numerical matrix, with data as the samples, and columns as samples  



```{r PCA}

## Install and load packages
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("PCAtools")

library(PCAtools)

## We will start our original data that has not been pivoted because this has the data we want as the columns
data <- read_csv("./Data_Carpentry_Workshop_2022/raw_data/Bolouri_2021_subset.csv")
View(data)
colnames(data)

## Now subset the data to the numerical columns of interest
data_subset <- data %>% select(Sample.ID, CBC.White.Blood.Cell.Count, CBC.Absolute.Monocytes, CBC.Absolute.Neutrophils, CBC.Absolute.Lymphocytes, FracCD45.Neutrophil, FracCD45.T.cell.CD4, FracCD45.DC, T.cell.CD8.HLA_DRp__of.CD8) %>% drop_na() 
# check the class of all our data to make sure it is numerical
str(data_subset) # we are good!

## Now we need to set the sample.id to be the rownames
data_subset_rownames <- data_subset %>% column_to_rownames(., var = "Sample.ID")

## now we can transpose and make a matrix
data_subset_mat <- as.matrix(t(data_subset_rownames))

## Next we can create our metadata matrix to go along with the data
  
# create metadata
metadata_subset = data %>% select(Sample.ID, sex, age, race,patientType, HighestCare, severity) %>%
  # keep only those sample with No NA data values 
  filter(Sample.ID %in% data_subset$Sample.ID) %>%
    # also make the rownames sample.ID
  column_to_rownames(., var = "Sample.ID")
  
# check CYTOF and CBC colnames match metadata rownames
all(colnames(data_subset_mat ) == rownames(metadata_subset)) # TRUE

# run PCA
pca <- PCAtools::pca(data_subset_mat,
                           metadata = metadata_subset)

# Plot PCA by different variable
pca_secerity <- PCAtools::biplot(pca, colby = "severity", colLegendTitle = "Severity", legendPosition = 'right')
pca_patient_type <- PCAtools::biplot(pca, colby = "patientType", colLegendTitle = "Patient Type", legendPosition = 'right')

pcas_comb <- ggarrange(pca_secerity ,  pca_patient_type, nrow = 1, ncol = 2 )

ggsave(pcas_comb, file = "./Data_Carpentry_Workshop_2022/figures/pcas.pdf", device = "pdf", height = 5, width = 12)



```

We can plot this same data now as a heatmap. Both heatmaps and PCAs require their data to be in a matrix format. One of the most popular and highly customizable packages for creating heatmaps is called `ComplexHeatmap`. This package is also well documented https://jokergoo.github.io/ComplexHeatmap-reference/book/ and allows you to create figures that are already in `ggplot2` format, which makes it easier to export the plots.

```{r heatmap}
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#
#BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)

# Create the complex heatmap
Heatmap(data_subset_mat) # it's as simple as this since we already have the matrix made!

# Now we can start adding customizations 
# we can build an annotation object, put in same order as the initial rownames
ha <- rowAnnotation(Type = c("CBC","CBC", "CBC","CBC","CYTOF","CYTOF","CYTOF","CYTOF"),
                                 col = list(Type = c("CBC" = "red", "CYTOF" = "blue")))

heatmap <- ComplexHeatmap::Heatmap(data_subset_mat, right_annotation = ha )
class(heatmap)


```


### 10:15-10:30: BREAK 

### 10:30-12:00pm: Loading and Customizing Code for your Analyses

This part of the workshop is going to be left open for Hannah and Matt Dufort to help participants learn how to customize code for their analyses.

